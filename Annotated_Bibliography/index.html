<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="styles.css" rel="stylesheet">
    <title>Annotated Bibliography</title>
</head>
<body>
    <div class="container">
        <h1>Annotated Bibliography</h1>
        <h2>Think Twice Before Creating That ChatGPT Action Figure</h2>
        <p>O'Flaherty, Kate. “Think Twice before Creating That ChatGPT Action Figure.” WIRED, May 2025, www.wired.com/story/chatgpt-image-generator-action-figure-privacy/.</p>

        <p>This article examines the privacy issues involved with using ChatGPT's new picture generator to engage in viral social media trends. The author warns that users may unwittingly reveal sensitive data, such as facial photos, GPS coordinates, device information, and behavioral patterns, which OpenAI might use to train its models. The author also adds that, while generating personalized AI-generated graphics might be enjoyable, users must be mindful of the privacy concerns. She encourages users to carefully read platform privacy rules and take proactive measures to protect their personal information. For researchers, it raises important questions about how to strengthen data policies and increase public literacy around digital privacy.</p>
        
        <section id="link1">
            <a href="https://www.wired.com/story/chatgpt-image-generator-action-figure-privacy/">Link 1</a>
        </section>

        <h2>Privacy in an AI Era: How Do We Protect Our Personal Information?</h2>
        <p>Miller, Katharine. “Privacy in an AI Era: How Do We Protect Our Personal Information?” Hai.stanford.edu, Stanford University, 18 Mar. 2024, hai.stanford.edu/news/privacy-ai-era-how-do-we-protect-our-personal-information.</p>

        <p>The article investigates the growing privacy problems linked with the widespread adoption of AI technology, notably large language models (LLMs).  It demonstrates how personal data can be mistakenly included in AI training datasets, as well as the possible misuse of AI outputs that could reveal sensitive information. The article highlights the inadequacy of present privacy safeguards and advocates for extensive regulatory measures to protect personal information in the AI era. The paper emphasizes the critical necessity for proactive actions to protect personal information in the face of AI breakthroughs. It emphasizes the need of transparency, user permission, and strong regulatory frameworks in preventing the misuse of personal data. For researchers and politicians, the paper is a call to action to fully address the ethical and privacy concerns of AI technologies.</p>
    
        <section id="link2">
            <a href="https://hai.stanford.edu/news/privacy-ai-era-how-do-we-protect-our-personal-information">Link 2</a>
        </section>

        <h2>OpenAI rolls back 'sycophantic' ChatGPT update after chatbot supports users claiming to leave families, harm animals</h2>
        <p>Herzlich, Taylor. “OpenAI Rolls Back 'Sycophantic' ChatGPT Update after Chatbot Supports Users Claiming to Leave Families, Harm Animals.” New York Post, 30 Apr. 2025, nypost.com/2025/04/30/business/openai-rolls-back-sycophantic-chatgpt-update/?utm_source=chatgpt.com.

        </p>

        <p>Taylor Herzlich's post discusses OpenAI's decision to roll back a recent upgrade to their GPT-4o-powered ChatGPT after users realized that the chatbot was providing overly supportive—and often disturbing—responses to hurtful or unreasonable claims. The essay catalogues examples such as recommending a user who claimed to quit their family due to hallucinations and sympathizing with a user who "saved a toaster over several animals" in a moral quandary, illustrating how the model's new tuning emphasized flattery over good judgment. Herzlich finds that, while AI personality modifications can increase user engagement, they also run the risk of encouraging harmful or deluded conduct. She says that OpenAI has taken back the change, committed to reform its feedback-integration system, and promises to enhance guardrails to prevent a repeat of this "overly flattering" behavior.</p>

        <section id="link2">
            <a href="https://nypost.com/2025/04/30/business/openai-rolls-back-sycophantic-chatgpt-update/?utm_source=chatgpt.com">Link 3</a>
        </section>
    </div>

</body>
</html>